import cv2
import numpy as np
import streamlit as st
import base64
from keras.models import load_model
from keras.preprocessing.image import img_to_array
#-------------------------backgroud---------------------------------
def get_img_as_base64(file):
    with open(file, "rb") as f:
        data = f.read()
    return base64.b64encode(data).decode()

img = get_img_as_base64("bc.jpg")

page_bg_img = f"""
<style>
[data-testid="stAppViewContainer"] > .main {{
background-image: url("https://images.unsplash.com/photo-1501426026826-31c667bdf23d");
background-size: 125%;
background-position: 30% 45%;
background-repeat: no-repeat;
background-attachment: local;
}}
[data-testid="stSidebar"] > div:first-child {{
background-image: url("data:image/png;base64,{img}");
background-position: 50% 45%;
background-size: 174%;
}}
[data-testid="stSidebarNav"] span {{
color:white;
}}
[data-testid="stHeader"] {{
background: rgba(0,0,0,0);
}}
[data-testid="stToolbar"] {{
right: 2rem;
}}
</style>
"""
st.markdown(page_bg_img, unsafe_allow_html=True)
with st.sidebar: 
    st.image("https://www.onepointltd.com/wp-content/uploads/2019/12/shutterstock_1166533285-Converted-02.png")
#----------------------------------------------------------------
import cv2
import numpy as np
import streamlit as st
import base64
from keras.models import load_model
from keras.preprocessing.image import img_to_array
# T·∫£i m√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán
model = load_model('FaceDetect_RealTime_final6.h5')
# T·∫£i b·ªô ph√¢n lo·∫°i Cascade c·ªßa khu√¥n m·∫∑t
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
# B·∫£n ƒë·ªì √°nh x·∫° gi·ªØa nh√£n v√† th√¥ng tin c√° nh√¢n
personal_info_map = {
    0: {'Name': 'None', 'ID': 'None', 'birthdate': 'None', 'major': 'None'},
    1: {'Name': '**Kim Thoa**', 'ID': '**20146076**', 'birthdate': '**16/02/2002**',
        'class':'**20146CL1A**', 'major': '**Mechatronics Engineering Technology**'},
    2: {'Name': '**Son Lam**', 'ID': '**20146362**', 'birthdate': '**09/06/2002**',
        'class':'**20146CL1A**', 'major': '**Mechatronics Engineering Technology**'},
    3: {'Name': '**Tan Vu**', 'ID': '**20146463**',  'birthdate': '**19/04/2002**',
        'class':'**20146CL1A**', 'major': '**Mechatronics Engineering Technology**'},
    4: {'Name': '**Quang Nhat**', 'ID': '**20146384**', 'birthdate': '**01/01/2002**',
        'class':'**20146CL1A**', 'major': '**Mechatronics Engineering Technology**'},
    5: {'Name': '**Anh Viet**', 'ID': '**20146216**', 'birthdate': '**18/09/2002**',
        'class':'**20146CL1A**', 'major': '**Mechatronics Engineering Technology**'},
    6: {'Name': '**Nghia Nguyen**', 'ID': '**20146373**', 'birthdate':'**05/05/2002**',
        'class':'**20146CL1A**', 'major': '**Mechatronics Engineering Technology**'},
    7: {'Name': '**Quoc Phong**', 'ID': '**20149078**', 'birthdate': '**26/06/2002**',
        'class':'**20146CL1A**', 'major': '**Mechatronics Engineering Technology**'},
    8: {'Name': '**Van Quyet**', 'ID': '**20146408**', 'birthdate': '**04/02/2002**',
        'class':'**20146CL1B**', 'major': '**Mechatronics Engineering Technology**'}
}
# Ti√™u ƒë·ªÅ cho ·ª©ng d·ª•ng v√† tr√¨nh t·∫£i t·ªáp l√™n
st.title(":red[FACE RECOGNITION]üòÄ")
# Ti√™u ƒë·ªÅ cho ·ª©ng d·ª•ng v√† tr√¨nh t·∫£i t·ªáp l√™n
st.header("Facial recognition and student information provisionüßë‚Äçüéì")
# T·∫£i t·ªáp tin l√™n Streamlit
uploaded_file= st.file_uploader("Choose an image...üìÇ", type=["jpg", "jpeg", "png","bmp"])
# Th·ª±c hi·ªán nh·∫≠n di·ªán khu√¥n m·∫∑t khi nh·∫•n n√∫t "Start face recognition"
if st.button('Start face recognitionüîç'):
    # Ki·ªÉm tra xem ƒë√£ t·∫£i t·ªáp l√™n ch∆∞a
    if uploaded_file is not None:
        st.write("Done!‚úÖ")
        # ƒê·ªçc t·ªáp ·∫£nh
        image = cv2.imdecode(np.fromstring(uploaded_file.read(), np.uint8), 1)
        # Thay ƒë·ªïi k√≠ch th∆∞·ªõc ·∫£nh
        resized_image = cv2.resize(image, (112, 112))
        # Chuy·ªÉn ƒë·ªïi ·∫£nh sang m√†u x√°m
        gray = cv2.cvtColor(resized_image, cv2.COLOR_BGR2GRAY)
        # √Åp d·ª•ng c√¢n b·∫±ng l∆∞·ª£c ƒë·ªì m√†u ƒë·ªÉ c·∫£i thi·ªán ƒë·ªô t∆∞∆°ng ph·∫£n
        gray = cv2.equalizeHist(gray)
        # √Åp d·ª•ng l·ªçc trung b√¨nh ƒë·ªÉ gi·∫£m nhi·ªÖu
        gray = cv2.medianBlur(gray, 5)
        # Nh·∫≠n di·ªán khu√¥n m·∫∑t trong ·∫£nh x√°m
        faces = face_cascade.detectMultiScale(gray, 1.3, 5)
        # X·ª≠ l√Ω t·ª´ng khu√¥n m·∫∑t ƒë∆∞·ª£c nh·∫≠n di·ªán
        for (x, y, w, h) in faces:
            # Tr√≠ch xu·∫•t v√πng khu√¥n m·∫∑t
            face = resized_image[y:y+h, x:x+w]
            # Thay ƒë·ªïi k√≠ch th∆∞·ªõc v√† chu·∫©n h√≥a ·∫£nh khu√¥n m·∫∑t
            resized_face = cv2.resize(face,(100, 100))
            # thay ƒë·ªïi k√≠ch th∆∞·ªõc th√†nh m·ªôt m·∫£ng NumPy
            normalized_face = img_to_array(resized_face)
            # Chu·∫©n h√≥a m·∫£ng NumPy b·∫±ng c√°ch chia t·∫•t c·∫£ c√°c gi√° tr·ªã trong m·∫£ng cho 255.0
            normalized_face = normalized_face.astype('float32')
            normalized_face = normalized_face / 255.0
            #L·∫≠t ng∆∞·ª£c khu√¥n m·∫∑t b·∫±ng ph∆∞∆°ng th·ª©c flip c·ªßa OpenCV ƒë·ªÉ tƒÉng kh·∫£ nƒÉng ph√°t hi·ªán khu√¥n m·∫∑t            
            flipped_face = cv2.flip(normalized_face, 1)
            reshaped_face = np.reshape(normalized_face, (1,100, 100,3))
            # D·ª± ƒëo√°n nh√£n c·ªßa khu√¥n m·∫∑t s·ª≠ d·ª•ng m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán
            prediction = model.predict(reshaped_face)
            label = np.argmax(prediction)
             # L·∫•y th√¥ng tin c√° nh√¢n c·ªßa nh√£n ƒë∆∞·ª£c d·ª± ƒëo√°n
            personal_info = personal_info_map[label]
            # T·∫°o vƒÉn b·∫£n ƒë·ªÉ hi·ªÉn th·ªã
            text = f"<br>Name: {personal_info['Name']}<br>ID: {personal_info['ID']}<br>DoB: {personal_info['birthdate']}<br>Class: {personal_info['class']}<br>Major: {personal_info['major']}"
            # V·∫Ω h√¨nh ch·ªØ nh·∫≠t xung quanh khu√¥n m·∫∑t ƒë∆∞·ª£c nh·∫≠n di·ªán
            cv2.rectangle(resized_image, (x, y), (x+w, y+h), (0, 255, 0), 2)
            # Hi·ªÉn th·ªã th√¥ng tin c√° nh√¢n c·ªßa nh√£n ƒë∆∞·ª£c d·ª± ƒëo√°n tr√™n giao di·ªán Streamlit
            st.write("The detected face belongs to:", text, unsafe_allow_html=True)
        # Hi·ªÉn th·ªã ·∫£nh ƒë√£ ƒë∆∞·ª£c x·ª≠ l√Ω tr√™n giao di·ªán Streamlit
        st.image(resized_image, channels="BGR")